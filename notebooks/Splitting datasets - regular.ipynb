{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ae87276d-904e-4f21-a551-972f6e96dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f374caa-9930-4743-b699-66ca74c15aa7",
   "metadata": {},
   "source": [
    "#### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b12bb62a-5846-4d1c-9c92-724606702119",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = 'nursery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ff27e437-d3c7-47de-a664-07b00e0d68c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>nursery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health    nursery  \n",
       "0  recommended  recommend  \n",
       "1     priority   priority  \n",
       "2    not_recom  not_recom  \n",
       "3  recommended  recommend  \n",
       "4     priority   priority  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent = '../datasets/'\n",
    "location = parent + repository + '/' + repository + '.csv'\n",
    "\n",
    "data = pd.read_csv(location, header=0)\n",
    "# print(len(data))\n",
    "# unique_ages = [1, 2, 24, 25, 26, 27, 29]\n",
    "# data = data[~data['age'].isin(unique_ages)].reset_index(drop=True)\n",
    "# print(len(data))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e8b84af-ccee-41be-a468-c17229ee0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aux = data[data['nursery'] == 'recommend'].reset_index(drop=True)\n",
    "# row_val = df_aux.iloc[[0]]\n",
    "# row_train = df_aux.iloc[[1]]\n",
    "# print(row_val)\n",
    "# print(row_train, '\\n')\n",
    "# df_aux\n",
    "\n",
    "# print(len(data))\n",
    "# data = data[data['nursery'] != 'recommend'].reset_index(drop=True)\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a664115-62f1-44be-8392-938925622835",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- ABALONE DATASET --- ###\n",
    "\n",
    "# double_ages = []\n",
    "# double_rows = []\n",
    "# for age in set(data['age']):        \n",
    "#     if len(data[data['age'] == age]) == 2:\n",
    "#         double_ages.append(age)\n",
    "#         df_aux = data[data['age'] == age].reset_index(drop=True)\n",
    "#         double_rows.append(df_aux.iloc[[0]])\n",
    "#         double_rows.append(df_aux.iloc[[1]])\n",
    "        \n",
    "# print(len(data))\n",
    "# data = data[~data['age'].isin(double_ages)].reset_index(drop=True)\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f92dc7d6-6b38-4176-8721-332c511e9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['sex', 'length', 'diameter', 'height', 'whole weight', 'shucked weight', 'viscera weight', 'shell weight', 'age']\n",
      "Class name: age\n"
     ]
    }
   ],
   "source": [
    "print('Columns:', data.columns.tolist())\n",
    "label_col = data.columns[-1]\n",
    "print('Class name:', label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15779adc-998f-4a27-a2ed-58bb8a9e2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentils(df):\n",
    "    s = df.groupby([df.columns[-1]]).size().astype(float)\n",
    "    total_sum = s.sum()\n",
    "    for i, count in enumerate(s):\n",
    "        new_value = count/total_sum\n",
    "        s[i] = new_value\n",
    "    print(s, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f3ec511-a5d8-41d0-8b6b-c4ae896915be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_percentils(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58730de3-688b-49c2-8dbc-d400e900900a",
   "metadata": {},
   "source": [
    "#### 2. Split into train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "598f0ea6-1d35-4033-9da1-f8cc777448bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split_train = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_index, leftover_index in split_train.split(data, data[data.columns[-1]]):\n",
    "    train_set = data.loc[train_index]\n",
    "    leftover_set = data.loc[leftover_index]\n",
    "\n",
    "leftover_set = leftover_set.reset_index(drop=True)\n",
    "    \n",
    "split_val = StratifiedShuffleSplit(n_splits=1, test_size=0.6667, random_state=26)\n",
    "for val_index, test_index in split_val.split(leftover_set, leftover_set[leftover_set.columns[-1]]):\n",
    "    val_set = leftover_set.loc[val_index]\n",
    "    test_set = leftover_set.loc[test_index]\n",
    "    \n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "val_set = val_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f3a0e92-4560-483b-8e9e-9906762f1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2917\n",
      "Test 835\n",
      "Validation 416\n",
      "Total: 4168\n",
      "%train: 0.6998560460652591\n",
      "%test: 0.2003358925143954\n",
      "%val: 0.09980806142034548\n"
     ]
    }
   ],
   "source": [
    "print('Train:', len(train_set))\n",
    "print('Test', len(test_set))\n",
    "print('Validation', len(val_set))\n",
    "len_total = len(train_set) + len(test_set) + len(val_set)\n",
    "print('Total:', len_total)\n",
    "print('%train:', len(train_set)/len_total)\n",
    "print('%test:', len(test_set)/len_total)\n",
    "print('%val:', len(val_set)/len_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc4819-2878-4d82-a3d6-4dd31dc16168",
   "metadata": {},
   "source": [
    "#### 3. Verify stratification of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ccc2075a-07ff-49e6-a823-e99a26bb728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_percentils(train_set)\n",
    "# print_percentils(test_set)\n",
    "# print_percentils(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66801408-1c89-405e-8645-d0c21f55b2d6",
   "metadata": {},
   "source": [
    "#### 4. Write fixed test, validation and train (100%) sets to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a4866e41-9459-418c-8ba9-1cc7c84ab1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(map(list, test_set.itertuples(index=False)))\n",
    "\n",
    "test_location = '../datasets/' + repository + '/regular/' + repository + '_' + 'test.csv'\n",
    "with open(test_location, \"w\") as f:\n",
    "    f.write(','.join(data.columns.tolist()) + '\\n')\n",
    "    for value in D:\n",
    "        a = ','.join([str(i if type(i) == str else round(i,2)).strip() for i in value[0:]]) + '\\n'\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b44d4244-dc5e-4298-ac2e-b69130a4ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randrange\n",
    "\n",
    "# for age in unique_rows:\n",
    "#     idx = randrange(len(train_set))\n",
    "#     train_set = pd.concat([train_set.iloc[:idx], age, train_set.iloc[idx:]]).reset_index(drop=True)\n",
    "\n",
    "# for i, age in enumerate(double_rows):\n",
    "#     if i%2 == 0:\n",
    "#         idx1 = randrange(len(train_set))\n",
    "#         train_set = pd.concat([train_set.iloc[:idx1], age, train_set.iloc[idx1:]]).reset_index(drop=True)\n",
    "#     else:\n",
    "#         idx2 = randrange(len(val_set))\n",
    "#         val_set = pd.concat([val_set.iloc[:idx2], age, val_set.iloc[idx2:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8378ba23-8a92-4d6c-9334-09e67429973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(map(list, val_set.itertuples(index=False)))\n",
    "\n",
    "val_location = '../datasets/' + repository + '/regular/' + repository + '_' + 'val.csv'\n",
    "with open(val_location, \"w\") as f:\n",
    "    f.write(','.join(data.columns.tolist()) + '\\n')\n",
    "    for value in D:\n",
    "        a = ','.join([str(i if type(i) == str else round(i,2)).strip() for i in value[0:]]) + '\\n'\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8809a80-7bc7-424d-818d-471f23d1cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = randrange(len(train_set))\n",
    "# print(idx)\n",
    "\n",
    "# train_set = pd.concat([train_set.iloc[:idx], row_train, train_set.iloc[idx:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bcecc35a-2194-486b-92c8-3471769ec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(map(list, train_set.itertuples(index=False)))\n",
    "\n",
    "train_location = '../datasets/' + repository + '/regular/' + repository + '_' + 'train_perc100.csv'\n",
    "with open(train_location, \"w\") as f:\n",
    "    f.write(','.join(data.columns.tolist()) + '\\n')\n",
    "    for value in D:\n",
    "        a = ','.join([str(i if type(i) == str else round(i,2)).strip() for i in value[0:]]) + '\\n'\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca09ce0-d646-4538-a1cd-f5d448a2377c",
   "metadata": {},
   "source": [
    "#### 5. Subsample training set to 1%, 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4b4e509c-bce2-4d31-844b-00ed08e08ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "perc = 1\n",
    "test_param = 1 - perc*0.01\n",
    "print(test_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "43dc67a2-8f41-42fb-b921-2726101aea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = train_set[train_set['nursery'] != 'recommend'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fdd83b22-c216-40b1-a0ac-5faa1b61bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = []\n",
    "# u = []\n",
    "# for age in set(train_set['age']):\n",
    "#     if len(train_set[train_set['age'] == age]) == 1:\n",
    "#         a.append(age)\n",
    "#         aux = train_set[train_set['age'] == age].reset_index(drop=True)\n",
    "#         u.append(aux.iloc[[0]])\n",
    "        \n",
    "# print(len(train_set))\n",
    "# train_set = train_set[~train_set['age'].isin(a)].reset_index(drop=True)\n",
    "# print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ae3d502-faba-4009-81fc-7860dd7f19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_subtrain = StratifiedShuffleSplit(n_splits=1, test_size=test_param, random_state=42)\n",
    "for subtrain_index, _index in split_subtrain.split(train_set, train_set[train_set.columns[-1]]):\n",
    "    df_subtrain = train_set.loc[subtrain_index]\n",
    "\n",
    "df_subtrain = df_subtrain.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84ab9127-dcfd-412f-b4c5-1d42497c36af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = set(train_set['age']) - set(df_subtrain['age'])\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ca90a26a-95af-4433-8d74-2d4e113e8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for age in diff:    \n",
    "    aux = train_set[train_set['age'] == age]\n",
    "    idx = random.choice(list(aux.index))\n",
    "    row = train_set.iloc[[idx]]\n",
    "\n",
    "    # append to train set in random position\n",
    "    new_idx = randrange(len(df_subtrain))\n",
    "    df_subtrain = pd.concat([df_subtrain.iloc[:new_idx], row, df_subtrain.iloc[new_idx:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bd87b65-166c-4b01-8d31-61e9dc8737de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in u:\n",
    "#     idx = randrange(len(df_subtrain))\n",
    "#     print(idx)\n",
    "\n",
    "#     df_subtrain = pd.concat([df_subtrain.iloc[:idx], row, df_subtrain.iloc[idx:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0c909-147e-41e3-ab67-cc58f361fbf4",
   "metadata": {},
   "source": [
    "Verify stratification of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5168655-f84b-4892-843a-00f8a6d2e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_percentils(df_subtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2ebda-bf24-4e87-b67f-fb35aaa74078",
   "metadata": {},
   "source": [
    "#### 6. Write training partitions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a276e4d1-4ba5-4807-b271-0f17db56a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = list(map(list, df_subtrain.itertuples(index=False)))\n",
    "\n",
    "train_location = '../datasets/' + repository + '/regular/' + repository + '_' + 'train' + '_perc' + str(perc) + '.csv'\n",
    "with open(train_location, \"w\") as f:\n",
    "    f.write(','.join(data.columns.tolist()) + '\\n')\n",
    "    for value in D:\n",
    "        a = ','.join([str(i if type(i) == str else round(i,2)).strip() for i in value[0:]]) + '\\n'\n",
    "        f.write(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b5057a35-b170-4f4b-adc7-cd705324a918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_subtrain['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a845dc-4fe5-43d4-a6f7-49a0ab02bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
